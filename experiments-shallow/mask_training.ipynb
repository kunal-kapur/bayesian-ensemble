{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beec3fdf-884c-4ba2-9187-1768bef216a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model import Net, MCMC\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288cf5a6",
   "metadata": {},
   "source": [
    "### Fixed-Mask with bayesian inference training\n",
    "This notebook evaluates the performance of the performance of using fixed dropout masks and evaluating a weighted average of them at inference time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736030d",
   "metadata": {},
   "source": [
    "#### We apply random and rotations and blur to make task harder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd47a49-430c-4746-8a71-37953fa95bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=180),\n",
    "    transforms.ToTensor(), transforms.GaussianBlur(kernel_size=11, sigma=(5, 7)),  # Stronger blur\n",
    "    transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3c082b-1ba0-43dc-bfe5-79b01d2b9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c569fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 8\n",
    "NUM_MASKS = 10\n",
    "LR = 0.001\n",
    "dropout_probs=[0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "decc1b4c-7e4d-4e68-a60c-ac114500ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "indices = torch.randperm(len(dataset1)).tolist()  # Shuffled once\n",
    "\n",
    "# Use SubsetRandomSampler to keep the same shuffle order on each epoch for the over-fitting step\n",
    "sampler = SequentialSampler(indices)  # Keeps the order fixed\n",
    "train_dataloader = DataLoader(dataset1, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "test_dataloader = DataLoader(dataset2, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f335f9",
   "metadata": {},
   "source": [
    "### Overfitting portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "112635f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(num_masks=NUM_MASKS, dropout_probs=dropout_probs)\n",
    "opt = Adam(model.parameters(), lr=LR)\n",
    "lossFn = torch.nn.NLLLoss() # Use NLL since we our model is outputting a probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9a859db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:09, 187.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 25297.0 / 60000: 0.42161666666666664\n",
      "Total loss: 3006.165900349617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:10, 179.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 33188.0 / 60000: 0.5531333333333334\n",
      "Total loss: 2381.466608762741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:10, 177.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 36524.0 / 60000: 0.6087333333333333\n",
      "Total loss: 2135.5018680095673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:10, 180.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 39234.0 / 60000: 0.6539\n",
      "Total loss: 1949.2740721404552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:10, 181.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 40614.0 / 60000: 0.6769\n",
      "Total loss: 1822.8774032592773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:09, 192.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 41838.0 / 60000: 0.6973\n",
      "Total loss: 1722.6279719173908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:09, 190.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 42675.0 / 60000: 0.71125\n",
      "Total loss: 1656.4186381697655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:10, 176.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 43452.0 / 60000: 0.7242\n",
      "Total loss: 1597.8344276845455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    model.train()\n",
    "    trainCorrect = 0\n",
    "    totalLoss = 0\n",
    "    for idx, (x, y)  in tqdm(enumerate(train_dataloader)):\n",
    "        logits = model.forward(x, mask = idx % NUM_MASKS)\n",
    "        loss = lossFn(logits, y)\n",
    "        totalLoss += loss.item()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        trainCorrect += (logits.argmax(1) == y).type(\n",
    "\t\t\ttorch.float).sum().item()\n",
    "    print(f\"Train Accuracy: {trainCorrect} / {len(dataset1)}: {trainCorrect/len(dataset1)}\")\n",
    "    print(f\"Total loss: {totalLoss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc8ebf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (dropout1): ConsistentMCDropout(p=0.4)\n",
       "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(num_masks=NUM_MASKS, dropout_probs=dropout_probs)\n",
    "model.load_state_dict(torch.load(\"../model.pth\", weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e19ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = MCMC(model=model, increment_amt=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76c30e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "train_dataloader = DataLoader(dataset1, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3892a64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:10, 173.16it/s]\n",
      "1875it [00:09, 193.48it/s]\n",
      "1875it [00:11, 164.10it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i in range(3):\n",
    "    trainCorrect = 0\n",
    "    for idx, (x, y)  in tqdm(enumerate(train_dataloader)):\n",
    "        mcmc.transition(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a9974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1081, 0.0988, 0.0961, 0.0999, 0.1006, 0.0980, 0.1058, 0.0965, 0.1002,\n",
      "        0.0960])\n"
     ]
    }
   ],
   "source": [
    "dist = torch.tensor([(val / mcmc.tot).item() for val in mcmc.ocurrences])\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef6a66ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 6])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "values, indices = torch.topk(dist, k=2)\n",
    "print(indices)\n",
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65dc967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kunalkapur/Workspace/bayesian-ensemble/model.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  keep_indices = torch.tensor(keep_indices, dtype=torch.long)\n",
      "10000it [00:07, 1389.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_correct = 0\n",
    "model.eval()\n",
    "for idx, (x, y)  in tqdm(enumerate(test_dataloader)):\n",
    "    # logits2 = model.forward(x, mask=1)\n",
    "    logits = mcmc.predict(x, chosen_masks=indices)\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    test_correct += (pred == y).sum().item()\n",
    "print(test_correct / len(dataset2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76628139",
   "metadata": {},
   "source": [
    "## Test accuracy was 76% which is a somewhat stronger than the controls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9d1ea0",
   "metadata": {},
   "source": [
    "### We show the number of overlapping neurons that can be pruned by finding the union-set of neurons between mask. In this case 212/256 neurons were used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7075951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([212])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_nonmasked = []\n",
    "for index in indices:\n",
    "    indices_nonmasked.append((torch.nonzero(model.dropout1.mask_dict[index.item()] == 0)))\n",
    "\n",
    "(torch.unique(torch.cat(tuple(indices_nonmasked)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476bd64b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
