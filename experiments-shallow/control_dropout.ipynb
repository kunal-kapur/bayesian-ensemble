{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beec3fdf-884c-4ba2-9187-1768bef216a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from models_control import NetNormalDropout\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb303e",
   "metadata": {},
   "source": [
    "### Control experiment: Not using masks with standard dropout\n",
    "This notebook evaluates the performance oof using a standard deep-net with 'normal' dropout layers in training which are removed at inferene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd47a49-430c-4746-8a71-37953fa95bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=180),\n",
    "    transforms.ToTensor(), transforms.GaussianBlur(kernel_size=7, sigma=(4, 5)),  # Stronger blur\n",
    "    transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3c082b-1ba0-43dc-bfe5-79b01d2b9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c569fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "NUM_MASKS = 1\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decc1b4c-7e4d-4e68-a60c-ac114500ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "train_dataloader = DataLoader(dataset1, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112635f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetNormalDropout()\n",
    "opt = Adam(model.parameters(), lr=LR)\n",
    "lossFn = torch.nn.NLLLoss() # Use NLL since we our model is outputting a probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a859db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:08, 229.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.49278333333333335\n",
      "Total loss: 2664.430910408497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:08, 226.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6377\n",
      "Total loss: 1970.7157387137413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:15, 122.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6768166666666666\n",
      "Total loss: 1740.2488400638103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:14, 133.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6879166666666666\n",
      "Total loss: 1659.981947928667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:13, 139.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7007833333333333\n",
      "Total loss: 1588.5666856765747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:14, 131.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7049833333333333\n",
      "Total loss: 1557.2589680850506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:14, 127.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7123833333333334\n",
      "Total loss: 1512.752326130867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:16, 112.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7198\n",
      "Total loss: 1482.9898345470428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:16, 112.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7247833333333333\n",
      "Total loss: 1449.2435713261366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:15, 121.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7239666666666666\n",
      "Total loss: 1447.843842536211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:14, 126.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7269\n",
      "Total loss: 1429.1121688783169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:15, 119.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7284166666666667\n",
      "Total loss: 1420.2725238204002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:17, 104.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.73275\n",
      "Total loss: 1396.3104232549667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:18, 99.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.73115\n",
      "Total loss: 1391.8905310034752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:22, 82.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.73525\n",
      "Total loss: 1378.7975038066506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    model.train()\n",
    "    trainCorrect = 0\n",
    "    totalLoss = 0\n",
    "    for idx, (x, y)  in tqdm(enumerate(train_dataloader)):\n",
    "        logits = model.forward(x)\n",
    "        loss = lossFn(logits, y)\n",
    "        totalLoss += loss.item()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        trainCorrect += (logits.argmax(1) == y).type(\n",
    "\t\t\ttorch.float).sum().item()\n",
    "    print(f\"Train Accuracy: {trainCorrect/len(dataset1)}\")\n",
    "    print(f\"Total loss: {totalLoss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c76d3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:02, 4395.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_correct = 0\n",
    "model.eval()\n",
    "for idx, (x, y)  in tqdm(enumerate(test_dataloader)):\n",
    "    logits = model.forward(x)\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    test_correct += (pred == y).sum().item()\n",
    "print(test_correct / len(dataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ebf46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19ded4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
