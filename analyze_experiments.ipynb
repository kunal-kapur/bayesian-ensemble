{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"tot_masks_trained\": Total number of masks used in training\n",
    "\n",
    "\"num_masks\": number of the \"top-k\" masks used when evaluating\n",
    "\n",
    "\"dropout_probs1\": Dropout probability on layer 1\n",
    "\n",
    "\"dropout_probs2\": Dropout probability on layer 2\n",
    "\n",
    "\"num_groups\": Number of partitioned groups for masks to train off of\n",
    "\n",
    "\"increment_amt\": amount to increment each mask when using MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"tot_masks_trained\", \"num_masks\",\n",
    "    \"test_accuracy\",\n",
    "    \"EPOCHS\",\n",
    "    \"BATCH_SIZE\",\n",
    "    \"LR\",\n",
    "    \"dropout_probs1\",\n",
    "    \"dropout_probs2\",\n",
    "    \"num_groups\",\n",
    "    \"increment_amt\"]\n",
    "df = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/7b4nn19d1rj3vsg11yxvc8lw0000gn/T/ipykernel_3141/2272338392.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_df])\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(\"experiments\"):\n",
    "    path = os.path.join(\"experiments\", folder)\n",
    "    # adding this because I forgot to add number of masks trained on in the csv\n",
    "    match = re.findall(r'\\d+', folder.split(\"_\")[0])[-1] \n",
    "    if \"results.csv\" not in os.listdir(path=path):\n",
    "        continue\n",
    "    new_df = pd.read_csv(os.path.join(path, \"results.csv\"))\n",
    "    new_df[\"tot_masks_trained\"] = match\n",
    "    df = pd.concat([df, new_df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High dropout probabilities do have the ability of yielding stronger performance. It would seem; however, there is a caveat that there must be fewer masks (but not necessarily only one) that we train on in general. \n",
    "\n",
    "I would hypotheisize that too many independent masks trying to train on their own end up adding too much noise to weights and don't allow them to learn meaningful representations.\n",
    "\n",
    "For this particular architecture (hidden layer size (256, 128)) it seems that 3 masks yields results that are somewhat close to a standard deep-net which uses all neurons (i.e dropout probabiltieies of [0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tot_masks_trained</th>\n",
       "      <th>num_masks</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>EPOCHS</th>\n",
       "      <th>BATCH_SIZE</th>\n",
       "      <th>LR</th>\n",
       "      <th>dropout_probs1</th>\n",
       "      <th>dropout_probs2</th>\n",
       "      <th>num_groups</th>\n",
       "      <th>increment_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tot_masks_trained num_masks  test_accuracy EPOCHS BATCH_SIZE     LR  \\\n",
       "3                 3         3         0.8963     12         32  0.001   \n",
       "3                 3         3         0.8963     12         32  0.001   \n",
       "3                 3         3         0.8963     12         32  0.001   \n",
       "2                 3         2         0.9017     12         32  0.001   \n",
       "2                 3         2         0.9017     12         32  0.001   \n",
       "2                 3         2         0.9017     12         32  0.001   \n",
       "3                 3         3         0.9085     12         32  0.001   \n",
       "3                 3         3         0.9085     12         32  0.001   \n",
       "3                 3         3         0.9085     12         32  0.001   \n",
       "\n",
       "   dropout_probs1  dropout_probs2 num_groups increment_amt  \n",
       "3             0.7             0.7          1            10  \n",
       "3             0.7             0.7          1            50  \n",
       "3             0.7             0.7          1             1  \n",
       "2             0.7             0.4          1             1  \n",
       "2             0.7             0.4          1            50  \n",
       "2             0.7             0.4          1            10  \n",
       "3             0.7             0.4          1             1  \n",
       "3             0.7             0.4          1            50  \n",
       "3             0.7             0.4          1            10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['test_accuracy'] > 0.89) & (df['dropout_probs1'] >= 0.7) & \\\n",
    "   (df['dropout_probs2'] >= 0.4)].sort_values(by=\"test_accuracy\").tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tot_masks_trained</th>\n",
       "      <th>num_masks</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>EPOCHS</th>\n",
       "      <th>BATCH_SIZE</th>\n",
       "      <th>LR</th>\n",
       "      <th>dropout_probs1</th>\n",
       "      <th>dropout_probs2</th>\n",
       "      <th>num_groups</th>\n",
       "      <th>increment_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9065</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9065</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9065</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tot_masks_trained num_masks  test_accuracy EPOCHS BATCH_SIZE     LR  \\\n",
       "2                 3         2         0.9057     12         32  0.001   \n",
       "3                 3         3         0.9065     12         32  0.001   \n",
       "3                 3         3         0.9065     12         32  0.001   \n",
       "3                 3         3         0.9065     12         32  0.001   \n",
       "2                 3         2         0.9080     12         32  0.001   \n",
       "2                 3         2         0.9080     12         32  0.001   \n",
       "2                 3         2         0.9080     12         32  0.001   \n",
       "2                 3         2         0.9084     12         32  0.001   \n",
       "2                 3         2         0.9084     12         32  0.001   \n",
       "2                 3         2         0.9084     12         32  0.001   \n",
       "3                 3         3         0.9085     12         32  0.001   \n",
       "3                 3         3         0.9085     12         32  0.001   \n",
       "3                 3         3         0.9085     12         32  0.001   \n",
       "3                 3         3         0.9088     12         32  0.001   \n",
       "3                 3         3         0.9088     12         32  0.001   \n",
       "3                 3         3         0.9088     12         32  0.001   \n",
       "3                 3         3         0.9105     12         32  0.001   \n",
       "3                 3         3         0.9105     12         32  0.001   \n",
       "3                 3         3         0.9105     12         32  0.001   \n",
       "1                 1         1         0.9146     12         32  0.001   \n",
       "\n",
       "   dropout_probs1  dropout_probs2 num_groups increment_amt  \n",
       "2             0.2             0.4          1             1  \n",
       "3             0.4             0.2          1            50  \n",
       "3             0.4             0.2          1            10  \n",
       "3             0.4             0.2          1             1  \n",
       "2             0.4             0.4          1             1  \n",
       "2             0.4             0.4          1            50  \n",
       "2             0.4             0.4          1            10  \n",
       "2             0.4             0.2          1             1  \n",
       "2             0.4             0.2          1            50  \n",
       "2             0.4             0.2          1            10  \n",
       "3             0.7             0.4          1            50  \n",
       "3             0.7             0.4          1             1  \n",
       "3             0.7             0.4          1            10  \n",
       "3             0.2             0.4          1            50  \n",
       "3             0.2             0.4          1            10  \n",
       "3             0.2             0.4          1             1  \n",
       "3             0.4             0.4          1            10  \n",
       "3             0.4             0.4          1            50  \n",
       "3             0.4             0.4          1             1  \n",
       "1             0.0             0.0          1             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['test_accuracy'] > 0.89)].sort_values(by=\"test_accuracy\").tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
