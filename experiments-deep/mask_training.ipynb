{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beec3fdf-884c-4ba2-9187-1768bef216a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model import NetV2, MCMC\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288cf5a6",
   "metadata": {},
   "source": [
    "### Fixed-Mask with bayesian inference training\n",
    "This notebook evaluates the performance of the performance of using fixed dropout masks and evaluating a weighted average of them at inference time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736030d",
   "metadata": {},
   "source": [
    "#### We apply random and rotations and blur to make task harder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd47a49-430c-4746-8a71-37953fa95bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=180),\n",
    "    transforms.ToTensor(), transforms.GaussianBlur(kernel_size=7, sigma=(4, 5)),  # Stronger blur\n",
    "    transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3c082b-1ba0-43dc-bfe5-79b01d2b9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c569fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "NUM_MASKS = 5\n",
    "LR = 0.001\n",
    "dropout_probs=[0.4, 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decc1b4c-7e4d-4e68-a60c-ac114500ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "indices = torch.randperm(len(dataset1)).tolist()  # Shuffled once\n",
    "\n",
    "# Use SubsetRandomSampler to keep the same shuffle order on each epoch for the over-fitting step\n",
    "sampler = SequentialSampler(indices)  # Keeps the order fixed\n",
    "train_dataloader = DataLoader(dataset1, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "test_dataloader = DataLoader(dataset2, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f335f9",
   "metadata": {},
   "source": [
    "### Overfitting portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112635f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetV2(num_masks=NUM_MASKS, dropout_probs=dropout_probs)\n",
    "opt = Adam(model.parameters(), lr=LR)\n",
    "lossFn = torch.nn.NLLLoss() # Use NLL since we our model is outputting a probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a859db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:26, 70.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 58851.0 / 100000: 0.58851\n",
      "Total loss: 3583.5722175836563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:25, 74.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 78537.0 / 100000: 0.78537\n",
      "Total loss: 2034.3618046939373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:26, 71.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 82927.0 / 100000: 0.82927\n",
      "Total loss: 1645.286963492632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:31, 59.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 84666.0 / 100000: 0.84666\n",
      "Total loss: 1477.6174337789416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:31, 59.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 85828.0 / 100000: 0.85828\n",
      "Total loss: 1371.9244211241603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:35, 53.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 86612.0 / 100000: 0.86612\n",
      "Total loss: 1294.7676348499954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:32, 57.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 87264.0 / 100000: 0.87264\n",
      "Total loss: 1243.6770866177976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:32, 58.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 87523.0 / 100000: 0.87523\n",
      "Total loss: 1192.9507208913565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:23, 78.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 88231.0 / 100000: 0.88231\n",
      "Total loss: 1154.3681839052588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:23, 80.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 88611.0 / 100000: 0.88611\n",
      "Total loss: 1115.5614146962762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:25, 72.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 88732.0 / 100000: 0.88732\n",
      "Total loss: 1109.8045058771968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:24, 76.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 88806.0 / 100000: 0.88806\n",
      "Total loss: 1090.1483276933432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:23, 81.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 89238.0 / 100000: 0.89238\n",
      "Total loss: 1061.869417335838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:22, 82.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 89488.0 / 100000: 0.89488\n",
      "Total loss: 1040.6780602792278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:24, 77.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 89519.0 / 100000: 0.89519\n",
      "Total loss: 1033.5377450855449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NGROUPS = 3 # dividing groups to use\n",
    "mask_groups = [list(range(i, NUM_MASKS, NGROUPS)) for i in range(NGROUPS)]  # Partition masks\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    trainCorrect = 0\n",
    "    totalLoss = 0\n",
    "    tot = 0\n",
    "    for idx, (x, y) in tqdm(enumerate(train_dataloader)):\n",
    "        group_id = idx % NGROUPS  # Assign batch to a group\n",
    "        masks = mask_groups[group_id]  # Get all masks in this group\n",
    "        \n",
    "        for mask in masks:\n",
    "            logits = model.forward(x, mask=mask)\n",
    "            loss = lossFn(logits, y)\n",
    "            totalLoss += loss.item()\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            trainCorrect += (logits.argmax(1) == y).type(torch.float).sum().item()\n",
    "            tot += len(y)\n",
    "\n",
    "    print(f\"Train Accuracy: {trainCorrect} / {tot}: {trainCorrect / tot}\")\n",
    "    print(f\"Total loss: {totalLoss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c76d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8ebf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NetV2(num_masks=NUM_MASKS, dropout_probs=dropout_probs)\n",
    "# model.load_state_dict(torch.load(\"../model.pth\", weights_only=True))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e19ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = MCMC(model=model, increment_amt=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d085d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "train_dataloader = DataLoader(dataset1, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3892a64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:17, 104.36it/s]\n",
      "1875it [00:15, 120.37it/s]\n",
      "1875it [00:14, 128.71it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i in range(3):\n",
    "    trainCorrect = 0\n",
    "    for idx, (x, y)  in tqdm(enumerate(train_dataloader)):\n",
    "        mcmc.transition(x=x, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a86dd5",
   "metadata": {},
   "source": [
    "This gives a bit more of a non-uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a9974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2153, 0.1761, 0.1937, 0.1733, 0.2416])\n"
     ]
    }
   ],
   "source": [
    "dist = torch.tensor([(val / mcmc.tot).item() for val in mcmc.ocurrences])\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a66ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 0])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "values, indices = torch.topk(dist, k=2)\n",
    "print(indices)\n",
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65dc967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kunalkapur/Workspace/bayesian-ensemble/experiments-deep/../model.py:249: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  keep_indices = torch.tensor(keep_indices, dtype=torch.long)\n",
      "10000it [00:12, 793.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with all masks: 0.9099\n",
      "Test accuracy with top 3: 0.9023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_correct_top_2 = 0\n",
    "test_correct = 0\n",
    "model.eval()\n",
    "for idx, (x, y)  in tqdm(enumerate(test_dataloader)):\n",
    "    # logits2 = model.forward(x, mask=1)\n",
    "    logits = mcmc.predict(x, chosen_masks=None)\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    test_correct += (pred == y).sum().item()\n",
    "\n",
    "\n",
    "    logits = mcmc.predict(x, chosen_masks=indices)\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    test_correct_top_2 += (pred == y).sum().item()\n",
    "print(f\"Test accuracy with all masks: {test_correct / len(dataset2)}\")\n",
    "print(f\"Test accuracy with top 3: {test_correct_top_2 / len(dataset2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76628139",
   "metadata": {},
   "source": [
    "####  First Layer (428 / 512) neurons taken\n",
    "#### Second layer (166 / 256) neurons taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7075951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([428])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_nonmasked = []\n",
    "for index in indices:\n",
    "    indices_nonmasked.append((torch.nonzero(model.dropout1.mask_dict[index.item()] == 0)))\n",
    "\n",
    "(torch.unique(torch.cat(tuple(indices_nonmasked)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "476bd64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([166])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_nonmasked = []\n",
    "for index in indices:\n",
    "    indices_nonmasked.append((torch.nonzero(model.dropout2.mask_dict[index.item()] == 0)))\n",
    "\n",
    "(torch.unique(torch.cat(tuple(indices_nonmasked)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd80ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
