{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beec3fdf-884c-4ba2-9187-1768bef216a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model import NetV2, MCMC\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288cf5a6",
   "metadata": {},
   "source": [
    "### Fixed-Masks with bayesian inference for training\n",
    "This notebook evaluates the performance of the performance of using fixed dropout masks and evaluating a weighted average of them at inference time.\n",
    "\n",
    "This notebook shows training and pruning for one of the better set of hyperparameters that also had higher dropout probabilities on each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736030d",
   "metadata": {},
   "source": [
    "#### We apply random and rotations and blur to make task harder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd47a49-430c-4746-8a71-37953fa95bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=180),\n",
    "    transforms.ToTensor(), transforms.GaussianBlur(kernel_size=7, sigma=(4, 5)),  # Stronger blur\n",
    "    transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3c082b-1ba0-43dc-bfe5-79b01d2b9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c569fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "NUM_MASKS = 3\n",
    "LR = 0.001\n",
    "dropout_probs=[0.7, 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decc1b4c-7e4d-4e68-a60c-ac114500ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "indices = torch.randperm(len(dataset1)).tolist()  # Shuffled once\n",
    "\n",
    "# Use SubsetRandomSampler to keep the same shuffle order on each epoch for the over-fitting step\n",
    "sampler = SequentialSampler(indices)  # Keeps the order fixed\n",
    "train_dataloader = DataLoader(dataset1, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "test_dataloader = DataLoader(dataset2, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f335f9",
   "metadata": {},
   "source": [
    "### Overfitting portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112635f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetV2(num_masks=NUM_MASKS, dropout_probs=dropout_probs)\n",
    "opt = Adam(model.parameters(), lr=LR)\n",
    "lossFn = torch.nn.NLLLoss() # Use NLL since we our model is outputting a probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a859db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:15, 123.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 112039.0 / 180000: 0.6224388888888889\n",
      "Total loss: 5982.230939865112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:15, 120.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 142833.0 / 180000: 0.7935166666666666\n",
      "Total loss: 3533.7145986557007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:14, 133.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 150362.0 / 180000: 0.8353444444444444\n",
      "Total loss: 2876.504527039826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:14, 133.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 153363.0 / 180000: 0.8520166666666666\n",
      "Total loss: 2605.307093206793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:14, 128.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 155368.0 / 180000: 0.8631555555555556\n",
      "Total loss: 2409.059836709872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:15, 119.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 156915.0 / 180000: 0.87175\n",
      "Total loss: 2282.3711749296635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:15, 119.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 157643.0 / 180000: 0.8757944444444444\n",
      "Total loss: 2218.7956836656667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:17, 107.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 158330.0 / 180000: 0.8796111111111111\n",
      "Total loss: 2142.3615517392755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:17, 108.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 159116.0 / 180000: 0.8839777777777778\n",
      "Total loss: 2085.7453461978585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:16, 113.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 159338.0 / 180000: 0.8852111111111111\n",
      "Total loss: 2062.041484077461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:16, 115.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 159677.0 / 180000: 0.8870944444444444\n",
      "Total loss: 2013.9672125540674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:16, 112.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 160029.0 / 180000: 0.88905\n",
      "Total loss: 2000.577449085191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:16, 114.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 160442.0 / 180000: 0.8913444444444445\n",
      "Total loss: 1944.8180303834379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:16, 115.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 160569.0 / 180000: 0.89205\n",
      "Total loss: 1957.5500510726124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:16, 114.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 160765.0 / 180000: 0.8931388888888889\n",
      "Total loss: 1939.1459698001854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NGROUPS = 1 # dividing groups to use\n",
    "mask_groups = [list(range(i, NUM_MASKS, NGROUPS)) for i in range(NGROUPS)]  # Partition masks\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    trainCorrect = 0\n",
    "    totalLoss = 0\n",
    "    tot = 0\n",
    "    for idx, (x, y) in tqdm(enumerate(train_dataloader)):\n",
    "        group_id = idx % NGROUPS  # Assign batch to a group\n",
    "        masks = mask_groups[group_id]  # Get all masks in this group\n",
    "        \n",
    "        for mask in masks:\n",
    "            logits = model.forward(x, mask=mask)\n",
    "            loss = lossFn(logits, y)\n",
    "            totalLoss += loss.item()\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            trainCorrect += (logits.argmax(1) == y).type(torch.float).sum().item()\n",
    "            tot += len(y)\n",
    "\n",
    "    print(f\"Train Accuracy: {trainCorrect} / {tot}: {trainCorrect / tot}\")\n",
    "    print(f\"Total loss: {totalLoss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c76d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8ebf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NetV2(num_masks=NUM_MASKS, dropout_probs=dropout_probs)\n",
    "# model.load_state_dict(torch.load(\"../model.pth\", weights_only=True))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e19ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = MCMC(model=model, increment_amt=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d085d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "train_dataloader = DataLoader(dataset1, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3892a64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:08, 229.72it/s]\n",
      "1875it [00:08, 221.45it/s]\n",
      "1875it [00:08, 222.32it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i in range(3):\n",
    "    trainCorrect = 0\n",
    "    for idx, (x, y)  in tqdm(enumerate(train_dataloader)):\n",
    "        mcmc.transition(x=x, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a86dd5",
   "metadata": {},
   "source": [
    "### Distribution ends up being close to uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a9974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3328, 0.3293, 0.3379])\n"
     ]
    }
   ],
   "source": [
    "dist = torch.tensor([(val / mcmc.tot).item() for val in mcmc.ocurrences])\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef6a66ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 1])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "values, indices = torch.topk(dist, k=3)\n",
    "print(indices)\n",
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65dc967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/kunalkapur/Workspace/bayesian-ensemble/experiments-deep/../model.py:251: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  keep_indices = torch.tensor(keep_indices, dtype=torch.long)\n",
      "10000it [00:06, 1477.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with all masks: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_correct_top_3 = 0\n",
    "test_correct = 0\n",
    "model.eval()\n",
    "for idx, (x, y)  in tqdm(enumerate(test_dataloader)):\n",
    "    # logits2 = model.forward(x, mask=1)\n",
    "    logits = mcmc.predict(x, chosen_masks=None)\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    test_correct += (pred == y).sum().item()\n",
    "\n",
    "\n",
    "    logits = mcmc.predict(x, chosen_masks=indices)\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    test_correct_top_3 += (pred == y).sum().item()\n",
    "print(f\"Test accuracy with all masks: {test_correct / len(dataset2)}\")\n",
    "# print(f\"Test accuracy with top 3: {test_correct_top_3 / len(dataset2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76628139",
   "metadata": {},
   "source": [
    "# Pruning\n",
    "\n",
    "We can take the union of all the masks used to see what neurons were needed in inference. \n",
    "\n",
    "####  First Layer (338 / 512) ~66% neurons need to be used \n",
    "#### Second layer (240 / 256) ~93% neurons need to be used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7075951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([338])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_nonmasked = []\n",
    "for index in indices:\n",
    "    indices_nonmasked.append((torch.nonzero(model.dropout1.mask_dict[index.item()] == 0)))\n",
    "\n",
    "(torch.unique(torch.cat(tuple(indices_nonmasked)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "476bd64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_nonmasked = []\n",
    "for index in indices:\n",
    "    indices_nonmasked.append((torch.nonzero(model.dropout2.mask_dict[index.item()] == 0)))\n",
    "\n",
    "(torch.unique(torch.cat(tuple(indices_nonmasked)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd80ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
